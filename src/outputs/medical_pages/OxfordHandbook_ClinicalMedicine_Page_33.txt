# Randomized controlled trials

In a randomized controlled trial (RCT), participants are allocated to an intervention/exposure (eg new drug treatment) or no intervention (eg placebo, standard care) by a process which equates to the flip of a coin, ie all participants have an equal chance of being in either arm of the study. The aim is to minimize bias and attempt to get at the truth as to whether the intervention is any good or not. Both groups are followed up and analysed against predefined end-points.

**Randomizing** Done with the aim of eliminating the effects of non-studied factors. With randomization (and sufficient study size) the two arms of the study will be identical (on average), with the exception of the intervention of interest.

**Blinding** There is a risk that factors during the trial may affect the outcome, eg participant or clinician optimism if they know the patient is on active treatment, or an unwillingness to expose more severe disease to placebo. If the subject does not know which intervention they are having, the trial is single-blind. Ideally, the experimenter should not know either, and the study should be double-blind.

> In a good trial, the blind lead the blind.

## Journal club: how good is this RCT?

- Does the study answer a useful question? Does it add to current literature: bigger, better, different target population?
- Does the target population in the study include your patient(s)? Check the inclusion and exclusion criteria including age and comorbidity.
- Is the intervention well described so it can be replicated in clinical practice?
- Was the sample size big enough to detect an effect? Can you find a sample size calculation? Watch out for sub-group analyses for which the sample size was not calculated.
- Were outcome measures predefined?
- Is randomization adequate? Look at the baseline data for each groupâ€”are there significant differences? Are any parameters of interest (that might affect outcome) not included?
- Who was blinded and how blind were they?
- Are statistical methods reported and appropriate? There should be a measure of the effect size and its precision (confidence interval, see p20).
- Is the effect clinically significant? Watch out for surrogate end-points which do not directly measure benefit, harm, or the treatment response of interest.
- How long was the follow-up? Was it long enough to determine outcome?
- How complete was the follow-up? How many patients were left at the end of the follow-up period? Were those who left the study included in the analysis (intention-to-treat)?

## When a randomized controlled trial might not be the best method

- Generating new ideas beyond current paradigms (case reports).
- Researching causes of illnesses and prognoses (cohort studies).
- Evaluating diagnostic tests (cohort study and decision model).
- Where the researcher has no idea of the effective dose of a drug (dose-ranging adaptive design).
- When recruiting of patients would be impossible or unethical.
- When personalized medicine is the aim, eg treatments matched to patients' biomarker profiles (adaptive design, cohort study).

In the end, all randomized trials have to submit to the ultimate test when the statistical collides with the personal: 'Will this treatment help me?', 'Will this procedure help you?' No randomized trial is complete until real-life decisions taken in the light of its findings are scrutinized. Remember Osler: 'no two individuals react alike and behave alike under the abnormal conditions which we know as disease. This is the fundamental difficulty of the physician'. Do not ask for definitive trials: everything is provisional.